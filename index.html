<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Tiantian Feng </title> <meta name="author" content="Tiantian Feng"> <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://tiantiaf0627.github.io/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">Tiantian's Homepage <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">Experiences </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Tiantian</span> Feng </h1> <p class="desc"><a href="https://sail.usc.edu/" rel="external nofollow noopener" target="_blank">SAIL Lab, University of Southern California</a>. tiantiaf@usc.edu</p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/tiantiaf-480.webp 480w,/assets/img/tiantiaf-800.webp 800w,/assets/img/tiantiaf-1400.webp 1400w," sizes="(min-width: 1200px) 351.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/tiantiaf.jpeg?254b6ddf98f14104c13ee6baf6f0af0e" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="tiantiaf.jpeg" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"> <p></p> </div> </div> <div class="clearfix"> <p>My name is Tiantian Feng, and I grew up in Leshan, China, which is famously for Leshan Giant Buddha. I studied both in Chengdu (both middle school and high school at Chengdu Foreign Language School) and Nanjing (Nanjing University of Posts and Telecommunications, undergraduate). I obtained my master degree at the University of Southern California afterwards. I recently completed my Ph.D. in the Thomas Lord Department of Computer Science at University of Southern California in 2023. I am fortunate to be advised by Professor Shrikanth Narayanan, a globally recognized scientist in speech modeling, linguistics, affective computing, and human understanding.</p> <p>My research focuses on leveraging sensors and computational methods for understanding natural human behaviors, also with a particular emphasis on inclusiveness and privacy. My research invovles wide range of applications such as speech understanding, multimodal understanding, and bio-signal processing. Additionally, I have hands-on experience in industrial sensor design and deploying sensors in research settings.</p> <p>I am currently a postdoc researcher in SAIL lab at USC, and I am actively looking for tenure-track or similar positions in academia. Don’t hesitate to contact me if you would like to collaborate.</p> </div> <h2> <a href="/news/" style="color: inherit">News</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">Apr 05, 2024</th> <td> I will be hosting Trustworthy Speech Processing Satellite Workshop at ICASSP 2024, April 15th, 2024 from 2:00 PM to 5:30 PM KST (Room AB203)! Please join us if you are interested in making speech processing safer, more private, and more inclusive! </td> </tr> <tr> <th scope="row" style="width: 20%">Jan 29, 2024</th> <td> Received 2024 ICASSP travel grant! </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 15, 2023</th> <td> 4 conference papers and 1 workshop paper got accepted to 2024 ICASSP! Congrats to all co-authors! </td> </tr> <tr> <th scope="row" style="width: 20%">Dec 11, 2023</th> <td> Successfully defended my Ph.D. thesis: Generative Foundation Model Assisted Privacy-Enhancing Computing in Human-Centered Machine Intelligence! </td> </tr> <tr> <th scope="row" style="width: 20%">Oct 27, 2023</th> <td> Received Outstanding Poster Presentation - 2023 Electrical Engineering Research Festival - Ming Hsieh Department of Electrical and Computer Engineering. </td> </tr> <tr> <th scope="row" style="width: 20%">Sep 11, 2023</th> <td> Oral presentation of my work funded by Amazon research at ACII 2023 in MIT Media Lab, Boston - PEFT-SER: On the use of parameter efficient transfer learning approaches for speech emotion recognition using pre-trained speech models! </td> </tr> <tr> <th scope="row" style="width: 20%">Aug 08, 2023</th> <td> Oral presentation of my work collabrated with Amazon Alexa and OSU at SIGKDD 2023 - FedMultimodal: A Benchmark for Multimodal Federated Learning! </td> </tr> <tr> <th scope="row" style="width: 20%">May 17, 2023</th> <td> 2 conference papers got accepted to 2023 INTERSPEECH! Congrats to all co-authors! </td> </tr> <tr> <th scope="row" style="width: 20%">May 16, 2023</th> <td> 1 conference papers got accepted to 2023 SIGKDD! Congrats to all co-authors! </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">Selected Publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Scientific Data</abbr> <abbr class="badge">Dataset</abbr> </div> <div id="mundnich2020tiles" class="col-sm-8"> <div class="title">TILES-2018, a longitudinal physiologic and behavioral data set of hospital workers</div> <div class="author"> Karel Mundnich , Brandon M Booth , Michelle l’Hommedieu , Tiantian Feng , Benjamin Girault , Justin L’hommedieu , Mackenzie Wildman , Sophia Skaaden , Amrutha Nadarajan , Jennifer L Villatte , and <span class="more-authors" title="click to view 1 more author" onclick=" var element=$(this); element.attr('title', ''); var more_authors_text=element.text() == '1 more author' ? ' others' : '1 more author'; var cursorPosition=0; var textAdder=setInterval(function(){ element.text(more_authors_text.substring(0, cursorPosition + 1)); if (++cursorPosition == more_authors_text.length){ clearInterval(textAdder); } }, '10'); ">1 more author</span> </div> <div class="periodical"> <em>Scientific Data</em>, 2020 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://tiles-data.isi.edu/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">mundnich2020tiles</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TILES-2018, a longitudinal physiologic and behavioral data set of hospital workers}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Mundnich, Karel and Booth, Brandon M and l'Hommedieu, Michelle and Feng, Tiantian and Girault, Benjamin and L'hommedieu, Justin and Wildman, Mackenzie and Skaaden, Sophia and Nadarajan, Amrutha and Villatte, Jennifer L and others}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{7}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{354}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2020}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature Publishing Group UK London}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Dataset}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Scientific Data</abbr> <abbr class="badge">Dataset</abbr> </div> <div id="yau2022tiles" class="col-sm-8"> <div class="title">TILES-2019: A longitudinal physiologic and behavioral data set of medical residents in an intensive care unit</div> <div class="author"> Joanna C Yau , Benjamin Girault , Tiantian Feng , Karel Mundnich , Amrutha Nadarajan , Brandon M Booth , Emilio Ferrara , Kristina Lerman , Eric Hsieh , and Shrikanth Narayanan </div> <div class="periodical"> <em>Scientific Data</em>, 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://tiles-data.isi.edu/" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Website</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">yau2022tiles</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TILES-2019: A longitudinal physiologic and behavioral data set of medical residents in an intensive care unit}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Yau, Joanna C and Girault, Benjamin and Feng, Tiantian and Mundnich, Karel and Nadarajan, Amrutha and Booth, Brandon M and Ferrara, Emilio and Lerman, Kristina and Hsieh, Eric and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific Data}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{9}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{536}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature Publishing Group UK London}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Dataset}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ACM Multimedia</abbr> <abbr class="badge">Dataset</abbr> </div> <div id="bose2023mm" class="col-sm-8"> <div class="title">MM-AU: Towards Multimodal Understanding of Advertisement Videos</div> <div class="author"> Digbalay Bose , Rajat Hebbar , Tiantian Feng , Krishna Somandepalli , Anfeng Xu , and Shrikanth Narayanan </div> <div class="periodical"> <em>In Proceedings of the 31st ACM International Conference on Multimedia</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">bose2023mm</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{MM-AU: Towards Multimodal Understanding of Advertisement Videos}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Bose, Digbalay and Hebbar, Rajat and Feng, Tiantian and Somandepalli, Krishna and Xu, Anfeng and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 31st ACM International Conference on Multimedia}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{86--95}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Dataset}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Preprint</abbr> <abbr class="badge">Generative AI</abbr> </div> <div id="feng2024can" class="col-sm-8"> <div class="title">Can Text-to-image Model Assist Multi-modal Learning for Visual Recognition with Visual Modality Missing?</div> <div class="author"> Tiantian Feng , Daniel Yang , Digbalay Bose , and Shrikanth Narayanan </div> <div class="periodical"> <em>arXiv preprint arXiv:2402.09036</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">feng2024can</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Can Text-to-image Model Assist Multi-modal Learning for Visual Recognition with Visual Modality Missing?}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Yang, Daniel and Bose, Digbalay and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2402.09036}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Generative AI}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Voice Privacy</abbr> <abbr class="badge">Generative AI</abbr> </div> <div id="feng2023unlocking" class="col-sm-8"> <div class="title">Unlocking Foundation Models for Privacy-Enhancing Speech Understanding: An Early Study on Low Resource Speech Training Leveraging Label-guided Synthetic Speech Content</div> <div class="author"> Tiantian Feng , Digbalay Bose , Xuan Shi , and Shrikanth Narayanan </div> <div class="periodical"> <em>arXiv preprint arXiv:2306.07791</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">feng2023unlocking</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Unlocking Foundation Models for Privacy-Enhancing Speech Understanding: An Early Study on Low Resource Speech Training Leveraging Label-guided Synthetic Speech Content}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Bose, Digbalay and Shi, Xuan and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2306.07791}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Generative AI}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Preprint</abbr> <abbr class="badge">Generative AI</abbr> </div> <div id="zhang2023gpt" class="col-sm-8"> <div class="title">GPT-FL: Generative pre-trained model-assisted federated learning</div> <div class="author"> Tuo Zhang* , Tiantian Feng* , Samiul Alam , Mi Zhang , Shrikanth S Narayanan , and Salman Avestimehr </div> <div class="periodical"> <em>arXiv preprint arXiv:2306.02210</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">zhang2023gpt</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{GPT-FL: Generative pre-trained model-assisted federated learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang*, Tuo and Feng*, Tiantian and Alam, Samiul and Zhang, Mi and Narayanan, Shrikanth S and Avestimehr, Salman}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2306.02210}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Generative AI}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Journal</abbr> <abbr class="badge">Trustworthiness</abbr> </div> <div id="feng2023review" class="col-sm-8"> <div class="title">A Review of Speech-centric Trustworthy Machine Learning: Privacy, Safety, and Fairness</div> <div class="author"> Tiantian Feng , Rajat Hebbar , Nicholas Mehlman , Xuan Shi , Aditya Kommineni , and Shrikanth Narayanan </div> <div class="periodical"> <em>APSIPA Transactions on Signal and Information Processing</em>, 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">feng2023review</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A Review of Speech-centric Trustworthy Machine Learning: Privacy, Safety, and Fairness}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Hebbar, Rajat and Mehlman, Nicholas and Shi, Xuan and Kommineni, Aditya and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{APSIPA Transactions on Signal and Information Processing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{12}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{3}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Now Publishers, Inc.}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Trustworthiness}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICASSP 2022</abbr> <abbr class="badge">Trustworthiness</abbr> </div> <div id="feng2022enhancing" class="col-sm-8"> <div class="title">Enhancing privacy through domain adaptive noise injection for speech emotion recognition</div> <div class="author"> Tiantian Feng , Hanieh Hashemi , Murali Annavaram , and Shrikanth S Narayanan </div> <div class="periodical"> <em>In ICASSP 2022-2022 IEEE international conference on acoustics, speech and signal processing (ICASSP)</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/usc-sail/speech-emotion-privacy-trust" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">feng2022enhancing</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Enhancing privacy through domain adaptive noise injection for speech emotion recognition}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Hashemi, Hanieh and Annavaram, Murali and Narayanan, Shrikanth S}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2022-2022 IEEE international conference on acoustics, speech and signal processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7702--7706}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Trustworthiness}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICASSP 2024</abbr> <abbr class="badge">Trustworthiness</abbr> </div> <div id="feng2024trust" class="col-sm-8"> <div class="title">TRUST-SER: On The Trustworthiness Of Fine-Tuning Pre-Trained Speech Embeddings For Speech Emotion Recognition</div> <div class="author"> Tiantian Feng , Rajat Hebbar , and Shrikanth Narayanan </div> <div class="periodical"> <em>In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/usc-sail/trust-ser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">feng2024trust</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{TRUST-SER: On The Trustworthiness Of Fine-Tuning Pre-Trained Speech Embeddings For Speech Emotion Recognition}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Hebbar, Rajat and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{11201--11205}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Trustworthiness}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">SIGKDD 2023</abbr> <abbr class="badge">Federated Learning</abbr> </div> <div id="feng2023fedmultimodal" class="col-sm-8"> <div class="title">FedMultimodal: A Benchmark for Multimodal Federated Learning</div> <div class="author"> Tiantian Feng , Digbalay Bose , Tuo Zhang , Rajat Hebbar , Anil Ramakrishna , Rahul Gupta , Mi Zhang , Salman Avestimehr , and Shrikanth Narayanan </div> <div class="periodical"> <em>In Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/usc-sail/fed-multimodal/tree/main" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">feng2023fedmultimodal</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FedMultimodal: A Benchmark for Multimodal Federated Learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Bose, Digbalay and Zhang, Tuo and Hebbar, Rajat and Ramakrishna, Anil and Gupta, Rahul and Zhang, Mi and Avestimehr, Salman and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 29th ACM SIGKDD Conference on Knowledge Discovery and Data Mining}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{4035--4045}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Federated Learning}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICASSP 2023</abbr> <abbr class="badge">Federated Learning</abbr> </div> <div id="zhang2023fedaudio" class="col-sm-8"> <div class="title">FedAudio: A federated learning benchmark for audio tasks</div> <div class="author"> Tuo Zhang , Tiantian Feng , Samiul Alam , Sunwoo Lee , Mi Zhang , Shrikanth S Narayanan , and Salman Avestimehr </div> <div class="periodical"> <em>In ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/zhang-tuo-pdf/FedAudio" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">zhang2023fedaudio</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{FedAudio: A federated learning benchmark for audio tasks}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Zhang, Tuo and Feng, Tiantian and Alam, Samiul and Lee, Sunwoo and Zhang, Mi and Narayanan, Shrikanth S and Avestimehr, Salman}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--5}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Federated Learning}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICASSP TSP 2024</abbr> <abbr class="badge">Federated Learning</abbr> </div> <div id="feng2024partial" class="col-sm-8"> <div class="title">Partial federated learning: Unlocking non-biometric text information sharing for federated learning</div> <div class="author"> Tiantian Feng , Anil Ramakrishna , Jimit Majmudar , Charith Peris , Jixuan Wang , Clement Chung , Richard Zemel , Morteza Ziyadi , and Rahul Gupta </div> <div class="periodical"> <em></em> 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">feng2024partial</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Partial federated learning: Unlocking non-biometric text information sharing for federated learning}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Ramakrishna, Anil and Majmudar, Jimit and Peris, Charith and Wang, Jixuan and Chung, Clement and Zemel, Richard and Ziyadi, Morteza and Gupta, Rahul}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP Workshops 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Federated Learning}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">INTERSPEECH 2022</abbr> <abbr class="badge">Federated Learning</abbr> </div> <div id="feng22b_interspeech" class="col-sm-8"> <div class="title">User-Level Differential Privacy against Attribute Inference Attack of Speech Emotion Recognition on Federated Learning</div> <div class="author"> Tiantian Feng , Raghuveer Peri , and Shrikanth Narayanan </div> <div class="periodical"> <em>In Proc. Interspeech 2022</em> , 2022 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/usc-sail/fed-ser-leakage" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">feng22b_interspeech</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Peri, Raghuveer and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{{User-Level Differential Privacy against Attribute Inference Attack of Speech Emotion Recognition on Federated Learning}}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2022}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proc. Interspeech 2022}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{5055--5059}</span><span class="p">,</span>
  <span class="na">doi</span> <span class="p">=</span> <span class="s">{10.21437/Interspeech.2022-10060}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Federated Learning}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICASSP 2024</abbr> <abbr class="badge">Foundation Model</abbr> </div> <div id="feng2024foundation" class="col-sm-8"> <div class="title">Foundation Model Assisted Automatic Speech Emotion Recognition: Transcribing, Annotating, and Augmenting</div> <div class="author"> Tiantian Feng , and Shrikanth Narayanan </div> <div class="periodical"> <em>In ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/usc-sail/foundation-ser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">feng2024foundation</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Foundation Model Assisted Automatic Speech Emotion Recognition: Transcribing, Annotating, and Augmenting}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2024-2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{12116--12120}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Foundation Model}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ACII 2023</abbr> <abbr class="badge">Foundation Model</abbr> </div> <div id="feng2023peft" class="col-sm-8"> <div class="title">PEFT-SER: On the use of parameter efficient transfer learning approaches for speech emotion recognition using pre-trained speech models</div> <div class="author"> Tiantian Feng , and Shrikanth Narayanan </div> <div class="periodical"> <em>In 2023 11th International Conference on Affective Computing and Intelligent Interaction (ACII)</em> , 2023 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/usc-sail/peft-ser" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">feng2023peft</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{PEFT-SER: On the use of parameter efficient transfer learning approaches for speech emotion recognition using pre-trained speech models}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2023 11th International Conference on Affective Computing and Intelligent Interaction (ACII)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{1--8}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2023}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Foundation Model}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Preprint</abbr> <abbr class="badge">Wearables</abbr> </div> <div id="feng2024understanding" class="col-sm-8"> <div class="title">Understanding Stress, Burnout, and Behavioral Patterns in Medical Residents Using Large-scale Longitudinal Wearable Recordings</div> <div class="author"> Tiantian Feng , and Shrikanth Narayanan </div> <div class="periodical"> <em>arXiv preprint arXiv:2402.09028</em>, 2024 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">feng2024understanding</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Understanding Stress, Burnout, and Behavioral Patterns in Medical Residents Using Large-scale Longitudinal Wearable Recordings}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{arXiv preprint arXiv:2402.09028}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2024}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Wearables}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Scientific Reports</abbr> <abbr class="badge">Wearables</abbr> </div> <div id="feng2021multimodal" class="col-sm-8"> <div class="title">A multimodal analysis of physical activity, sleep, and work shift in nurses with wearable sensor data</div> <div class="author"> Tiantian Feng , Brandon M Booth , Brooke Baldwin-Rodrı́guez , Felipe Osorno , and Shrikanth Narayanan </div> <div class="periodical"> <em>Scientific reports</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/usc-sail/tiles-day-night/tree/main" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">feng2021multimodal</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{A multimodal analysis of physical activity, sleep, and work shift in nurses with wearable sensor data}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Booth, Brandon M and Baldwin-Rodr{\'\i}guez, Brooke and Osorno, Felipe and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{Scientific reports}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{11}</span><span class="p">,</span>
  <span class="na">number</span> <span class="p">=</span> <span class="s">{1}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{8693}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{Nature Publishing Group UK London}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Wearables}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ACM Transactions</abbr> <abbr class="badge">Wearables</abbr> </div> <div id="jati2021temporal" class="col-sm-8"> <div class="title">Temporal dynamics of workplace acoustic scenes: Egocentric analysis and prediction</div> <div class="author"> Arindam Jati , Amrutha Nadarajan , Raghuveer Peri , Karel Mundnich , Tiantian Feng , Benjamin Girault , and Shrikanth Narayanan </div> <div class="periodical"> <em>IEEE/ACM Transactions on Audio, Speech, and Language Processing</em>, 2021 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@article</span><span class="p">{</span><span class="nl">jati2021temporal</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Temporal dynamics of workplace acoustic scenes: Egocentric analysis and prediction}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Jati, Arindam and Nadarajan, Amrutha and Peri, Raghuveer and Mundnich, Karel and Feng, Tiantian and Girault, Benjamin and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">journal</span> <span class="p">=</span> <span class="s">{IEEE/ACM Transactions on Audio, Speech, and Language Processing}</span><span class="p">,</span>
  <span class="na">volume</span> <span class="p">=</span> <span class="s">{29}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{756--769}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2021}</span><span class="p">,</span>
  <span class="na">publisher</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Wearables}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">Mobisys Workshop</abbr> <abbr class="badge">Wearables</abbr> </div> <div id="feng2018tiles" class="col-sm-8"> <div class="title">Tiles Audio Recorder: An Unobtrusive Wearable Solution to Track Audio Activity</div> <div class="author"> Tiantian Feng , Amrutha Nadarajan , Colin Vaz , Brandon Booth , and Shrikanth Narayanan </div> <div class="periodical"> <em>In Proceedings of the 4th ACM Workshop on Wearable Systems and Applications</em> , 2018 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://github.com/tiantiaf0627/tiles-audio-recorder/tree/main" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">feng2018tiles</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Tiles Audio Recorder: An Unobtrusive Wearable Solution to Track Audio Activity}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Nadarajan, Amrutha and Vaz, Colin and Booth, Brandon and Narayanan, Shrikanth}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{Proceedings of the 4th ACM Workshop on Wearable Systems and Applications}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{33--38}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2018}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Wearables}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-2 abbr"> <abbr class="badge">ICASSP 2019</abbr> <abbr class="badge">Wearables</abbr> </div> <div id="feng2019discovering" class="col-sm-8"> <div class="title">Discovering optimal variable-length time series motifs in large-scale wearable recordings of human bio-behavioral signals</div> <div class="author"> Tiantian Feng , and Shrikanth S Narayanan </div> <div class="periodical"> <em>In ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</em> , 2019 </div> <div class="periodical"> </div> <div class="links"> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">feng2019discovering</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Discovering optimal variable-length time series motifs in large-scale wearable recordings of human bio-behavioral signals}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Feng, Tiantian and Narayanan, Shrikanth S}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{7615--7619}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
  <span class="na">abbr2</span> <span class="p">=</span> <span class="s">{Wearables}</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li> </ol> </div> <div class="social"> <div class="contact-icons"> <a href="mailto:%74%69%61%6E%74%69%61%66@%75%73%63.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=p7oF-XIAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/tiantiaf0627" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/tiantian-feng-b4367989" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/tiantiaf" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> <a href="/feed.xml" title="RSS Feed"><i class="fa-solid fa-square-rss"></i></a> </div> <div class="contact-note">You can even add a little note about which of these is the best way to reach you. </div> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Tiantian Feng. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>